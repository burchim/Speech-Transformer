{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"prepare_dataset.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNvdEnH1nl5DBIpsBfeMvHx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"MbZHuwqW_GAx","colab_type":"text"},"source":["<center> \n","    <h1> Speech Transformer : A Speech to Text Transformer in TensorFlow 2 </h1>\n","    <h2> Librispeech Preprocessing </h2>\n","</center>"]},{"cell_type":"code","metadata":{"id":"jNbVBe9CXt20","colab_type":"code","colab":{}},"source":["!pip install tensorflow-io"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7X2oW8gJDHXG","colab_type":"code","colab":{}},"source":["import librosa\n","import pickle\n","import os\n","import sys\n","import tensorflow as tf\n","import tensorflow_io as tfio"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-vMeUoskxQBa","colab_type":"text"},"source":["#Librispeech Download"]},{"cell_type":"code","metadata":{"id":"ddv1ywbfDFPM","colab_type":"code","colab":{}},"source":["#6.3GB 100 hours training dataset\n","!curl --header \"Host: www.openslr.org\" --header \"User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36\" --header \"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header \"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" \"http://www.openslr.org/resources/12/train-clean-100.tar.gz\" -L -o 'train-clean-100.tar.gz'\n","!tar xvzf train-clean-100.tar.gz\n","\n","#23GB 360 hours training dataset\n","!curl --header \"Host: www.openslr.org\" --header \"User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.61 Safari/537.36\" --header \"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header \"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" --header \"Referer: http://www.openslr.org/12\" \"http://www.openslr.org/resources/12/train-clean-360.tar.gz\" -L -o 'train-clean-360.tar.gz'\n","!tar xvzf train-clean-360.tar.gz\n","\n","#30GB 500 hours training dataset\n","!curl --header \"Host: www.openslr.org\" --header \"User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.61 Safari/537.36\" --header \"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header \"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" --header \"Referer: http://www.openslr.org/12\" \"http://www.openslr.org/resources/12/train-other-500.tar.gz\" -L -o 'train-other-500.tar.gz'\n","!tar xvzf train-other-500.tar.gz\n","\n","#dev-clean validation set\n","!curl --header \"Host: www.openslr.org\" --header \"User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.116 Safari/537.36\" --header \"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header \"Accept-Language: en-GB,en-US;q=0.9,en;q=0.8\" --header \"Referer: http://www.openslr.org/12/\" \"http://www.openslr.org/resources/12/dev-clean.tar.gz\" -L -o 'dev-clean.tar.gz'\n","!tar xvzf dev-clean.tar.gz"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qn8bhuysxXga","colab_type":"text"},"source":["#Training set preprocessing"]},{"cell_type":"markdown","metadata":{"id":"UPj_ai74xt3P","colab_type":"text"},"source":["##Train Clean"]},{"cell_type":"code","metadata":{"id":"9KB_-Jr-DO0e","colab_type":"code","colab":{}},"source":["spec = []\n","speech = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sFe2h2z3DRXw","colab_type":"code","colab":{}},"source":["path = 'LibriSpeech/train-clean-100'\n","i=1\n","for rep1 in os.listdir(path):\n","    sys.stdout.write(\"\\r{}/{}\".format(i,len(os.listdir(path))))\n","    i+=1\n","    for rep2 in os.listdir(os.path.join(path,rep1)):\n","        for file in os.listdir(os.path.join(path,rep1,rep2)):\n","            if file[-4:] == '.txt':\n","                file = open(os.path.join(path,rep1,rep2,file),'r')\n","                for line in file.readlines():\n","                    A = librosa.core.load(os.path.join(path,rep1,rep2,line.split()[0] + '.flac'),sr=16000)[0]\n","                    \n","                    S = tfio.experimental.audio.spectrogram(A, nfft=512, window=400, stride=160)\n","                    S = tfio.experimental.audio.melscale(S, rate=16000, mels=80, fmin=0, fmax=8000)\n","                    S = tf.math.log(S+1e-9)\n","                    S = (S - tf.math.reduce_mean(S))/tf.math.reduce_std(S)\n","                    S = tf.cast(25*S, tf.int8)\n","                    \n","                    spec.append(S)\n","                    speech.append(line[len(line.split()[0]):].lower().replace('\\n','')[1:])\n","                    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XB2YR7G-xNln","colab_type":"code","colab":{}},"source":["print(\"{} audio\".format(len(spec)))\n","print(\"{} speech\".format(len(speech)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a8qqIs4pwuUQ","colab_type":"code","colab":{}},"source":["with open(\"pickled_LibriSpeech_clean100_10ms.pkl\", \"bw\") as f:\n","    data = (spec, speech)\n","    pickle.dump(data, f, protocol=4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xH0xKikODWyM","colab_type":"code","colab":{}},"source":["path = 'LibriSpeech/train-clean-360'\n","i=1\n","for rep1 in os.listdir(path):\n","    sys.stdout.write(\"\\r{}/{}\".format(i,len(os.listdir(path))))\n","    i+=1\n","    for rep2 in os.listdir(os.path.join(path,rep1)):\n","        for file in os.listdir(os.path.join(path,rep1,rep2)):\n","            if file[-4:] == '.txt':\n","                file = open(os.path.join(path,rep1,rep2,file),'r')\n","                for line in file.readlines():\n","                    A = librosa.core.load(os.path.join(path,rep1,rep2,line.split()[0] + '.flac'),sr=16000)[0]\n","                    \n","                    S = tfio.experimental.audio.spectrogram(A, nfft=512, window=400, stride=160)\n","                    S = tfio.experimental.audio.melscale(S, rate=16000, mels=80, fmin=0, fmax=8000)\n","                    S = tf.math.log(S+1e-9)\n","                    S = (S - tf.math.reduce_mean(S))/tf.math.reduce_std(S)\n","                    S = tf.cast(25*S, tf.int8)\n","                    \n","                    spec.append(S)\n","                    speech.append(line[len(line.split()[0]):].lower().replace('\\n','')[1:])\n","                    \n","      "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MMHlsSV_xLdV","colab_type":"code","colab":{}},"source":["print(\"{} audio\".format(len(spec)))\n","print(\"{} speech\".format(len(speech)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NtMLCbQwDlj4","colab_type":"code","colab":{}},"source":["with open(\"pickled_LibriSpeech_clean_10ms.pkl\", \"bw\") as f: # train-clean-100 + train-clean-360\n","    data = (spec, speech)\n","    pickle.dump(data, f, protocol=4)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CoratiMrx38p","colab_type":"text"},"source":["##Train Other"]},{"cell_type":"code","metadata":{"id":"JAyJQNG7wY_1","colab_type":"code","colab":{}},"source":["spec = []\n","speech = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"az-Uz8hnDbwl","colab_type":"code","colab":{}},"source":["path = 'LibriSpeech/train-other-500'\n","i=1\n","for rep1 in os.listdir(path):\n","    sys.stdout.write(\"\\r{}/{}\".format(i,len(os.listdir(path))))\n","    i+=1\n","    for rep2 in os.listdir(os.path.join(path,rep1)):\n","        for file in os.listdir(os.path.join(path,rep1,rep2)):\n","            if file[-4:] == '.txt':\n","                file = open(os.path.join(path,rep1,rep2,file),'r')\n","                for line in file.readlines():\n","                    A = librosa.core.load(os.path.join(path,rep1,rep2,line.split()[0] + '.flac'),sr=16000)[0]\n","                    \n","                    S = tfio.experimental.audio.spectrogram(A, nfft=512, window=400, stride=160)\n","                    S = tfio.experimental.audio.melscale(S, rate=16000, mels=80, fmin=0, fmax=8000)\n","                    S = tf.math.log(S+1e-9)\n","                    S = (S - tf.math.reduce_mean(S))/tf.math.reduce_std(S)\n","                    S = tf.cast(25*S, tf.int8)\n","                    \n","                    spec.append(S)\n","                    speech.append(line[len(line.split()[0]):].lower().replace('\\n','')[1:])\n","                    \n","         "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3r2Fk4XVxJnV","colab_type":"code","colab":{}},"source":["print(\"{} audio\".format(len(spec)))\n","print(\"{} speech\".format(len(speech)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TrcZ2eA3wzYx","colab_type":"code","colab":{}},"source":["with open(\"pickled_LibriSpeech_other_10ms.pkl\", \"bw\") as f:\n","    data = (spec, speech)\n","    pickle.dump(data, f, protocol=4)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WVn_qlYExemk","colab_type":"text"},"source":["#Validation set preprocessing"]},{"cell_type":"markdown","metadata":{"id":"HuUYEqxcyEVH","colab_type":"text"},"source":["##Dev Clean"]},{"cell_type":"code","metadata":{"id":"H3ItPHt5w3SJ","colab_type":"code","colab":{}},"source":["spec = []\n","speech = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Of7kniEyDdxI","colab_type":"code","colab":{}},"source":["path = 'LibriSpeech/dev-clean'\n","i=1\n","for rep1 in os.listdir(path):\n","    sys.stdout.write(\"\\r{}/{}\".format(i,len(os.listdir(path))))\n","    i+=1\n","    for rep2 in os.listdir(os.path.join(path,rep1)):\n","        for file in os.listdir(os.path.join(path,rep1,rep2)):\n","            if file[-4:] == '.txt':\n","                file = open(os.path.join(path,rep1,rep2,file),'r')\n","                for line in file.readlines():\n","                    A = librosa.core.load(os.path.join(path,rep1,rep2,line.split()[0] + '.flac'),sr=16000)[0]\n","                    \n","                    S = tfio.experimental.audio.spectrogram(A, nfft=512, window=400, stride=160)\n","                    S = tfio.experimental.audio.melscale(S, rate=16000, mels=80, fmin=0, fmax=8000)\n","                    S = tf.math.log(S+1e-9)\n","                    S = (S - tf.math.reduce_mean(S))/tf.math.reduce_std(S)\n","                    S = tf.cast(25*S, tf.int8)\n","                    \n","                    spec.append(S)\n","                    speech.append(line[len(line.split()[0]):].lower().replace('\\n','')[1:])\n","                    \n","        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iy8pwg-8Dil5","colab_type":"code","colab":{}},"source":["print(\"{} audio\".format(len(spec)))\n","print(\"{} speech\".format(len(speech)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5m40GCaLw-s2","colab_type":"code","colab":{}},"source":["with open(\"pickled_LibriSpeech_dev_clean_10ms.pkl\", \"bw\") as f:\n","    data = (spec, speech)\n","    pickle.dump(data, f, protocol=4)"],"execution_count":null,"outputs":[]}]}