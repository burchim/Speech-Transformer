{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"speech_transformer.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ejtTBIeu-1PX","colab_type":"text"},"source":["<center> \n","    <h1> Speech Transformer : A Speech to Text Transformer in TensorFlow 2 </h1>\n","    <h2> Training and Decoding </h2>\n","</center>"]},{"cell_type":"code","metadata":{"id":"gOsCCStJYsrg","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tbVwoDP6Yxg7","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import os\n","import matplotlib.pyplot as plt\n","import sys\n","import pickle\n","from tensorflow_addons.image import sparse_image_warp\n","import tensorflow_datasets as tfds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FZSrc0PGY0Sn","colab_type":"code","colab":{}},"source":["class Config:\n","\n","    def __init__(self):\n","\n","        #training\n","        self.TPU = True\n","        self.TRAIN = True\n","        self.EPOCHS = 15\n","        self.DTYPE = tf.bfloat16\n","        self.BATCH_SIZE = 128\n","        self.LABEL_SMOOTHING = 0.2\n","        self.NEIGHBORHOOD_SMOOTHING = False\n","        self.WARMUP_STEPS = 4000\n","        self.K = 1.5\n","        self.BETA1 = 0.9\n","        self.BETA2 = 0.98\n","        self.EPS = 1e-9\n","        self.AUG = True\n","\n","        #model\n","        self.N_ENC = 3\n","        self.N_DEC = 3 \n","        self.UNITS = 2048 \n","        self.D_MODEL = 512 \n","        self.NUM_HEADS = 8 \n","        self.DROPOUT = 0.1\n","        self.CNN = True\n","\n","        #samples\n","        self.ENCODING = 'subword' # subword / character \n","        self.MAX_SAMPLE = float('inf')\n","        self.MAX_LENGTH = 75 # 75 subword / 250 character\n","        self.MAX_SPEC_LENGTH = 1600\n","        self.D_SPEC = 80\n","        self.VOCAB_SIZE = None\n","        self.START_TOKEN = None\n","        self.END_TOKEN = None\n","        self.MAX_POSITION_ENCODING = None\n","\n","        #saves\n","        self.DATASET_PATH = 'path/to/dataset'\n","        self.CALLBACKS_PATH = 'path/to/callback'\n","        self.LOAD = True\n","        self.SAVED_MODEL = 'checkpoints.h5'\n","\n","        #decoding\n","        self.BEAM_SIZE = 10\n","        self.MAX_REP = 2 # 2 subword / 3 character \n","\n","C = Config()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OSVk6rkE-2fu","colab_type":"code","colab":{}},"source":["if C.TPU:\n","    # Create distribution strategy\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.experimental.TPUStrategy(tpu)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pv73XIVnY5vX","colab_type":"text"},"source":["#Prepare Dataset"]},{"cell_type":"code","metadata":{"id":"BrsThJ_tY6nP","colab_type":"code","colab":{}},"source":["#load the whole dataset for training\n","#else only load the 100 hours version\n","\n","if C.TRAIN:\n","    with open(os.path.join(C.DATASET_PATH, \"pickled_LibriSpeech_clean_10ms.pkl\"), \"br\") as f:\n","        data = pickle.load(f)\n","    spec1 = data[0]\n","    speech1 = data[1]\n","\n","    with open(os.path.join(C.DATASET_PATH, \"pickled_LibriSpeech_other_10ms.pkl\"), \"br\") as f:\n","        data = pickle.load(f)\n","    spec2 = data[0]\n","    speech2 = data[1]\n","\n","    spec_train = spec1 + spec2\n","    speech_train = speech1 + speech2\n","    print(\"{} training spec\".format(len(spec_train)))\n","    print(\"{} training speech\".format(len(speech_train)))\n","else:\n","    with open(os.path.join(C.DATASET_PATH, \"pickled_LibriSpeech_clean100_10ms.pkl\"), \"br\") as f:\n","        data = pickle.load(f)\n","    spec_train = data[0]\n","    speech_train = data[1]\n","    print(\"{} training spec\".format(len(spec_train)))\n","    print(\"{} training speech\".format(len(speech_train)))\n","\n","with open(os.path.join(C.DATASET_PATH, \"pickled_LibriSpeech_dev_clean_10ms.pkl\"), \"br\") as f:\n","    data = pickle.load(f)\n","spec_val = data[0]\n","speech_val = data[1]\n","print(\"{} validation spec\".format(len(spec_val)))\n","print(\"{} validation speech\".format(len(speech_val)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NigHGjdTY9dR","colab_type":"code","colab":{}},"source":["if not os.path.isfile(os.path.join(C.CALLBACKS_PATH,'tokenizer.pkl')):\n","    if C.ENCODING == 'subword':\n","        tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(speech_train+speech_val, target_vocab_size=2**13)\n","    else:\n","        tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=True)\n","        tokenizer.fit_on_texts(speech_train)\n","\n","    if not os.path.isdir(C.CALLBACKS_PATH):\n","        os.mkdir(C.CALLBACKS_PATH)\n","    with open(os.path.join(C.CALLBACKS_PATH,'tokenizer.pkl'), 'bw') as f:\n","        pickle.dump(tokenizer, f, protocol=4)\n","else:\n","    with open(os.path.join(C.CALLBACKS_PATH,'tokenizer.pkl'), 'br') as f:\n","        tokenizer = pickle.load(f)\n","\n","if C.ENCODING == 'subword':\n","    C.START_TOKEN, C.END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n","    C.VOCAB_SIZE = tokenizer.vocab_size + 2\n","else:\n","    C.START_TOKEN, C.END_TOKEN = [len(tokenizer.word_counts) + 1], [len(tokenizer.word_counts) + 2]\n","    C.VOCAB_SIZE = len(tokenizer.word_counts) + 3\n","print(\"VOCAB_SIZE = {}\".format(C.VOCAB_SIZE))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AV9uxlje_bbP","colab_type":"code","colab":{}},"source":["if C.MAX_SPEC_LENGTH == None:\n","    max = 0\n","    for S in spec_train:\n","        max = tf.maximum(max, S.shape[0])\n","    C.MAX_SPEC_LENGTH = max\n","    print('MAX_SPEC_LENGTH :', C.MAX_SPEC_LENGTH.numpy())\n","\n","if C.MAX_LENGTH == None:\n","    max = 0\n","    for s in speech_train:\n","        if C.ENCODING == 'subword':\n","            max = tf.maximum(max, len(tokenizer.encode(s))+2)\n","        else:\n","            max = tf.maximum(max, len(tokenizer.texts_to_sequences([s])[0])+2)\n","    C.MAX_LENGTH = max\n","    print('MAX_LENGTH :', C.MAX_LENGTH.numpy())\n","\n","if C.MAX_POSITION_ENCODING == None:\n","    C.MAX_POSITION_ENCODING = tf.maximum(C.MAX_LENGTH, C.MAX_SPEC_LENGTH)\n","    print('MAX_POSITION_ENCODING :', C.MAX_POSITION_ENCODING.numpy())\n","\n","\n","if not os.path.isdir(C.CALLBACKS_PATH):\n","    os.mkdir(C.CALLBACKS_PATH)\n","with open(os.path.join(C.CALLBACKS_PATH,'config.pkl'), 'bw') as f:\n","    pickle.dump(C, f, protocol=4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fSgIw05WZBWV","colab_type":"code","colab":{}},"source":["tokenized_speech_train = []\n","spec_audio_train = []\n","s=0\n","for (S,spe) in zip(spec_train, speech_train):\n","    if C.ENCODING == 'subword':\n","        spe = C.START_TOKEN + tokenizer.encode(spe) + C.END_TOKEN\n","    else:\n","        spe = C.START_TOKEN + tokenizer.texts_to_sequences([spe])[0] + C.END_TOKEN\n","\n","    if len(spe) <= C.MAX_LENGTH and len(S) <= C.MAX_SPEC_LENGTH:\n","        tokenized_speech_train.append(spe)\n","        S = tf.cast(S/25, C.DTYPE)\n","        S = tf.concat([S,tf.zeros((C.MAX_SPEC_LENGTH-len(S),C.D_SPEC), dtype=C.DTYPE)], axis=0)\n","\n","        spec_audio_train.append(S)\n","\n","        s+=1\n","        sys.stdout.write(\"\\r{}/{}\".format(s,C.MAX_SAMPLE))\n","        if s==C.MAX_SAMPLE:\n","            break\n","\n","tokenized_speech_train = tf.keras.preprocessing.sequence.pad_sequences(tokenized_speech_train, maxlen=C.MAX_LENGTH, padding='post')\n","\n","print()\n","print(\"{} training tokenized speech\".format(len(tokenized_speech_train)))\n","print(\"{} training spectrogram\".format(len(spec_audio_train)))\n","\n","\n","tokenized_speech_val = []\n","spec_audio_val = []\n","s=0\n","for (S,spe) in zip(spec_val, speech_val):\n","    if C.ENCODING == 'subword':\n","        spe = C.START_TOKEN + tokenizer.encode(spe) + C.END_TOKEN\n","    else:\n","        spe = C.START_TOKEN + tokenizer.texts_to_sequences([spe])[0] + C.END_TOKEN\n","\n","    if len(spe) <= C.MAX_LENGTH and len(S) <= C.MAX_SPEC_LENGTH:\n","        tokenized_speech_val.append(spe)\n","        S = tf.cast(S/25, C.DTYPE)\n","        S = tf.concat([S,tf.zeros((C.MAX_SPEC_LENGTH-len(S),C.D_SPEC), dtype=C.DTYPE)], axis=0)\n","\n","        spec_audio_val.append(S)\n","\n","        s+=1\n","        sys.stdout.write(\"\\r{}/{}\".format(s,C.MAX_SAMPLE))\n","        if s==C.MAX_SAMPLE:\n","            break\n","\n","tokenized_speech_val = tf.keras.preprocessing.sequence.pad_sequences(tokenized_speech_val, maxlen=C.MAX_LENGTH, padding='post')\n","\n","print()\n","print(\"{} validation tokenized speech\".format(len(tokenized_speech_val)))\n","print(\"{} validation spectrogram\".format(len(spec_audio_val)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tzgbj9pzbGAq","colab_type":"code","colab":{}},"source":["def freq_mask(input, param, name=None):\n","    freq_max = tf.shape(input)[1]\n","    f = tf.random.uniform(shape=(), minval=0, maxval=param, dtype=tf.dtypes.int32)\n","    f0 = tf.random.uniform(\n","        shape=(), minval=0, maxval=freq_max - f, dtype=tf.dtypes.int32\n","    )\n","    indices = tf.reshape(tf.range(freq_max), (1, -1))\n","    condition = tf.math.logical_and(\n","        tf.math.greater_equal(indices, f0), tf.math.less(indices, f0 + f)\n","    )\n","    return tf.where(condition, tf.cast(0.0, C.DTYPE), input)\n","\n","def sparse_warp(mel_spectrogram, param):\n","\n","    mel_spectrogram = tf.expand_dims(tf.expand_dims(mel_spectrogram, axis=0), axis=-1)#(1, T, F, 1)\n","    mel_spectrogram = tf.cast(mel_spectrogram, tf.float32)\n","\n","    fbank_size = tf.shape(mel_spectrogram)\n","    T, F = fbank_size[1], fbank_size[2]\n","\n","    pt = tf.random.uniform([], param, T-param, tf.int32)\n","    src_ctr_pt_freq = [F//2]\n","    src_ctr_pt_time = tf.ones_like(src_ctr_pt_freq) * pt\n","    src_ctr_pts = tf.stack((src_ctr_pt_time, src_ctr_pt_freq), -1)\n","    src_ctr_pts = tf.cast(src_ctr_pts, dtype=tf.float32)\n","\n","    w = tf.random.uniform([], -param, param, tf.int32)\n","    dest_ctr_pt_freq = src_ctr_pt_freq\n","    dest_ctr_pt_time = src_ctr_pt_time + w\n","    dest_ctr_pts = tf.stack((dest_ctr_pt_time, dest_ctr_pt_freq), -1)\n","    dest_ctr_pts = tf.cast(dest_ctr_pts, dtype=tf.float32)\n","\n","    source_control_point_locations = tf.expand_dims(src_ctr_pts, 0)\n","    dest_control_point_locations = tf.expand_dims(dest_ctr_pts, 0) \n","\n","    warped_image, _ = sparse_image_warp(mel_spectrogram,\n","                                        source_control_point_locations,\n","                                        dest_control_point_locations, \n","                                        num_boundary_points=1)\n","    return tf.cast(warped_image, C.DTYPE)[0,:,:,0]\n","\n","def augment(inputs, outputs):\n","    \"\"\"\n","    (LD) Librispeech Double policy augmentation without time masking\n","    F = 27\n","    W = 80\n","    p = 100%\n","    \"\"\"\n","    inputs['inputs'] = sparse_warp(inputs['inputs'], param=80)\n","    inputs['inputs'] = freq_mask(inputs['inputs'], param=27)\n","    inputs['inputs'] = freq_mask(inputs['inputs'], param=27)\n","    return inputs, outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OR_lROIrZD93","colab_type":"code","colab":{}},"source":["dataset_train = tf.data.Dataset.from_tensor_slices((\n","    {\n","        'inputs': spec_audio_train,\n","        'dec_inputs': tokenized_speech_train[:, :-1]\n","    },\n","    {\n","        'outputs': tokenized_speech_train[:, 1:]\n","    },\n","))\n","dataset_train = dataset_train.cache()\n","dataset_train = dataset_train.shuffle(buffer_size=len(spec_audio_train))\n","if C.AUG:\n","    dataset_train = dataset_train.map(augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n","dataset_train = dataset_train.batch(C.BATCH_SIZE, drop_remainder=True)\n","dataset_train = dataset_train.prefetch(tf.data.experimental.AUTOTUNE)\n","print(dataset_train)\n","\n","dataset_val = tf.data.Dataset.from_tensor_slices((\n","    {\n","        'inputs': spec_audio_val,\n","        'dec_inputs': tokenized_speech_val[:, :-1]\n","    },\n","    {\n","        'outputs': tokenized_speech_val[:, 1:]\n","    },\n","))\n","dataset_val = dataset_val.cache()\n","dataset_val = dataset_val.shuffle(buffer_size=len(spec_audio_val))\n","dataset_val = dataset_val.batch(C.BATCH_SIZE, drop_remainder=True)\n","dataset_val = dataset_val.prefetch(tf.data.experimental.AUTOTUNE)\n","print(dataset_val)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wp8NrxGWZIkP","colab_type":"text"},"source":["#Model"]},{"cell_type":"code","metadata":{"id":"3Vu1rXvWZMO3","colab_type":"code","colab":{}},"source":["def scaled_dot_product_attention(query, key, value, mask):\n","  \"\"\"Calculate the attention weights. \"\"\"\n","  matmul_qk = tf.matmul(query, key, transpose_b=True)\n","\n","  # scale matmul_qk\n","  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n","  logits = matmul_qk / tf.math.sqrt(depth)\n","\n","  # add the mask to zero out padding tokens\n","  if mask is not None:\n","    logits += (mask * -1e9)\n","\n","  # softmax is normalized on the last axis (seq_len_k)\n","  attention_weights = tf.nn.softmax(logits, axis=-1)\n","\n","  output = tf.matmul(attention_weights, value)\n","\n","  return output\n","\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","\n","  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n","    super(MultiHeadAttention, self).__init__(name=name)\n","    self.num_heads = num_heads\n","    self.d_model = d_model\n","\n","    assert d_model % self.num_heads == 0\n","\n","    self.depth = d_model // self.num_heads\n","\n","    self.query_dense = tf.keras.layers.Dense(units=d_model)\n","    self.key_dense = tf.keras.layers.Dense(units=d_model)\n","    self.value_dense = tf.keras.layers.Dense(units=d_model)\n","\n","    self.dense = tf.keras.layers.Dense(units=d_model)\n","\n","  def split_heads(self, inputs, batch_size):\n","    inputs = tf.reshape(\n","        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n","    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n","\n","  def call(self, inputs):\n","    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n","        'value'], inputs['mask']\n","    batch_size = tf.shape(query)[0]\n","\n","    # linear layers\n","    query = self.query_dense(query)\n","    key = self.key_dense(key)\n","    value = self.value_dense(value)\n","\n","    # split heads\n","    query = self.split_heads(query, batch_size)\n","    key = self.split_heads(key, batch_size)\n","    value = self.split_heads(value, batch_size)\n","\n","    # scaled dot-product attention\n","    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n","\n","    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n","\n","    # concatenation of heads\n","    concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n","\n","    # final linear layer\n","    outputs = self.dense(concat_attention)\n","\n","    return outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BXhotyC3ZO9p","colab_type":"code","colab":{}},"source":["def create_padding_mask(x):\n","  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n","  # (batch_size, 1, 1, sequence length)\n","  return mask[:, tf.newaxis, tf.newaxis, :]\n","\n","def create_look_ahead_mask(x):\n","  seq_len = tf.shape(x)[1]\n","  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n","  padding_mask = create_padding_mask(x)\n","  return tf.maximum(look_ahead_mask, padding_mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DlstkZ2PZZQA","colab_type":"code","colab":{}},"source":["class PositionalEncoding(tf.keras.layers.Layer):\n","\n","  def __init__(self, position, d_model):\n","    super(PositionalEncoding, self).__init__()\n","    self.pos_encoding = self.positional_encoding(position, d_model)\n","\n","  def get_angles(self, position, i, d_model):\n","    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n","    return position * angles\n","\n","  def positional_encoding(self, position, d_model):\n","    angle_rads = (self.get_angles(\n","        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n","        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n","        d_model=d_model)).numpy()\n","    \n","    # apply sin to even indices in the array; 2i\n","    angle_rads[:, 0::2] = tf.math.sin(angle_rads[:, 0::2])\n","    \n","    # apply cos to odd indices in the array; 2i+1\n","    angle_rads[:, 1::2] = tf.math.cos(angle_rads[:, 1::2])\n","    pos_encoding = angle_rads[tf.newaxis, ...]\n","\n","    return tf.cast(pos_encoding, tf.float32)\n","\n","  def call(self, inputs):\n","    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BaHvJDKLZcbo","colab_type":"code","colab":{}},"source":["def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n","  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n","\n","  attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs)\n","  attention = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention\")({\n","          'query': attention,\n","          'key': attention,\n","          'value': attention,\n","          'mask': padding_mask\n","      })\n","  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n","  attention = attention + inputs\n","\n","  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention)\n","  outputs = tf.keras.layers.Dense(units=units, activation='relu')(outputs)\n","  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n","  outputs = outputs + attention\n","\n","  return tf.keras.Model(inputs=[inputs, padding_mask],\n","                        outputs=outputs,\n","                        name=name)\n","\n","def encoder(maximum_position_encoding,\n","            num_layers,\n","            units,\n","            d_model,\n","            num_heads,\n","            dropout,\n","            name=\"encoder\"):\n","  inputs = tf.keras.Input(shape=(None,d_model,), name=\"inputs\")\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n","\n","  embeddings = inputs\n","      \n","  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n","  embeddings = PositionalEncoding(maximum_position_encoding, d_model)(embeddings)\n","\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n","\n","  for i in range(num_layers):\n","    outputs = encoder_layer(\n","        units=units,\n","        d_model=d_model,\n","        num_heads=num_heads,\n","        dropout=dropout,\n","        name=\"encoder_layer_{}\".format(i),\n","    )([outputs, padding_mask])\n","\n","  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs)\n","\n","  return tf.keras.Model(inputs=[inputs, padding_mask],\n","                        outputs=outputs,\n","                        name=name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Pzo4xzJZnzH","colab_type":"code","colab":{}},"source":["def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n","  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n","  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n","  look_ahead_mask = tf.keras.Input(shape=(1, None, None), name=\"look_ahead_mask\")\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n","\n","  attention1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs)\n","  attention1 = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention_1\")(inputs={\n","          'query': attention1,\n","          'key': attention1,\n","          'value': attention1,\n","          'mask': look_ahead_mask\n","      })\n","  attention1 = tf.keras.layers.Dropout(rate=dropout)(attention1)\n","  attention1 = attention1 + inputs\n","\n","  attention2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention1)\n","  attention2 = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention_2\")(inputs={\n","          'query': attention2,\n","          'key': enc_outputs,\n","          'value': enc_outputs,\n","          'mask': padding_mask\n","      })\n","  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n","  attention2 = attention2 + attention1\n","\n","  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention2)\n","  outputs = tf.keras.layers.Dense(units=units, activation='relu')(outputs)\n","  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n","  outputs = outputs + attention2\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n","      outputs=outputs,\n","      name=name)\n","  \n","def decoder(vocab_size,\n","            maximum_position_encoding,\n","            num_layers,\n","            units,\n","            d_model,\n","            num_heads,\n","            dropout,\n","            name='decoder'):\n","  inputs = tf.keras.Input(shape=(None,), name='inputs')\n","  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n","  look_ahead_mask = tf.keras.Input(shape=(1, None, None), name='look_ahead_mask')\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n","  \n","  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n","  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n","  embeddings = PositionalEncoding(maximum_position_encoding, d_model)(embeddings)\n","\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n","\n","  for i in range(num_layers):\n","    outputs = decoder_layer(\n","        units=units,\n","        d_model=d_model,\n","        num_heads=num_heads,\n","        dropout=dropout,\n","        name='decoder_layer_{}'.format(i),\n","    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n","\n","  outputs = tf.keras.layers.LayerNormalization(epsilon=1e-6)(outputs)\n","\n","  return tf.keras.Model(inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n","                        outputs=outputs,\n","                        name=name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6TApTf9WZ0ip","colab_type":"code","colab":{}},"source":["def transformer(vocab_size,\n","                maximum_position_encoding,\n","                num_layers_enc,\n","                num_layers_dec,\n","                units,\n","                d_spec,\n","                d_model,\n","                num_heads,\n","                dropout,\n","                cnn,\n","                name=\"transformer\"):\n","  inputs = tf.keras.Input(shape=(None,d_spec), name=\"inputs\")\n","  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n","\n","  if cnn:\n","      x = tf.expand_dims(inputs, axis=-1)\n","\n","      #block 1\n","      x = tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu')(x)\n","      x = tf.keras.layers.Conv2D(32, (3,3), padding='same', activation='relu')(x)\n","      x = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n","\n","      #block2\n","      x = tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu')(x)\n","      x = tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu')(x)\n","      x = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2))(x)\n","\n","      x = tf.keras.layers.Reshape((-1,(d_spec//4)*64))(x)\n","      inputs_strided = tf.keras.layers.MaxPool1D(pool_size=4, strides=4)(inputs)\n","  else:\n","      x = inputs\n","      inputs_strided = inputs\n","      \n","  x = tf.keras.layers.Dense(d_model)(x)\n","\n","  inputs_masks = tf.dtypes.cast(     \n","      tf.math.reduce_sum(\n","      inputs_strided,\n","      axis=2,\n","      keepdims=False,\n","  ), tf.int32)\n","\n","  #creating padding mask\n","  enc_padding_mask = tf.keras.layers.Lambda(create_padding_mask, output_shape=(1, 1, None),name='enc_padding_mask')(inputs_masks)\n","\n","  # mask the future tokens for decoder inputs at the 1st attention block\n","  look_ahead_mask = tf.keras.layers.Lambda(create_look_ahead_mask,output_shape=(1, None, None),name='look_ahead_mask')(dec_inputs)\n","\n","  # mask the encoder outputs for the 2nd attention block\n","  dec_padding_mask = tf.keras.layers.Lambda(create_padding_mask, output_shape=(1, 1, None),name='dec_padding_mask')(inputs_masks)\n","\n","  enc_outputs = encoder(\n","      maximum_position_encoding=maximum_position_encoding,\n","      num_layers=num_layers_enc,\n","      units=units,\n","      d_model=d_model,\n","      num_heads=num_heads,\n","      dropout=dropout,\n","  )(inputs=[x, enc_padding_mask])\n","\n","  dec_outputs = decoder(\n","      vocab_size=vocab_size,\n","      maximum_position_encoding=maximum_position_encoding,\n","      num_layers=num_layers_dec,\n","      units=units,\n","      d_model=d_model,\n","      num_heads=num_heads,\n","      dropout=dropout,\n","  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n","\n","  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n","\n","  return tf.keras.Model(inputs=[inputs, dec_inputs],\n","                        outputs=outputs,\n","                        name=name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iLzy8MGpaRL9","colab_type":"code","colab":{}},"source":["def loss_function(y_true, y_pred):\n","\n","  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n","  N = tf.math.count_nonzero(mask, dtype=tf.float32)\n","\n","  if C.NEIGHBORHOOD_SMOOTHING:\n","      y_true_smoothed = neighborhood_smoothing(y_true)\n","  else:\n","      y_true_smoothed = tf.one_hot(tf.cast(y_true, tf.int32), C.VOCAB_SIZE, on_value=1-C.LABEL_SMOOTHING, off_value=C.LABEL_SMOOTHING/C.VOCAB_SIZE)\n","\n","  loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True, reduction='none')(y_true_smoothed , y_pred)\n","  loss = tf.multiply(loss, mask)\n","\n","  return tf.math.reduce_sum(loss)/N\n","\n","def neighborhood_smoothing(y_true):\n","    y_true = tf.cast(y_true, tf.int32)\n","    y_true_masked = tf.where(y_true!=0, y_true, -1)\n","\n","    y_true_one_hot = tf.one_hot(y_true_masked, C.VOCAB_SIZE, on_value=1-C.LABEL_SMOOTHING)\n","\n","    y_true_shift_left_2 = tf.roll(y_true_masked, -2, axis=1)\n","    y_true_shift_left_2_one_hot = tf.one_hot(y_true_shift_left_2, C.VOCAB_SIZE, on_value=C.LABEL_SMOOTHING/6)\n","\n","    y_true_shift_left_1 = tf.roll(y_true_masked, -1, axis=1)\n","    y_true_shift_left_1_one_hot = tf.one_hot(y_true_shift_left_1, C.VOCAB_SIZE, on_value=C.LABEL_SMOOTHING/3)\n","\n","    y_true_shift_right_1 = tf.roll(y_true_masked, 1, axis=1)\n","    y_true_shift_right_1_one_hot = tf.one_hot(y_true_shift_right_1, C.VOCAB_SIZE, on_value=C.LABEL_SMOOTHING/3)\n","\n","    y_true_shift_right_2 = tf.roll(y_true_masked, 2, axis=1)\n","    y_true_shift_right_2_one_hot = tf.one_hot(y_true_shift_right_2, C.VOCAB_SIZE, on_value=C.LABEL_SMOOTHING/6)\n","\n","    y_true_smoothed = tf.math.reduce_max([y_true_shift_left_2_one_hot, y_true_shift_left_1_one_hot, y_true_one_hot, y_true_shift_right_1_one_hot, y_true_shift_right_2_one_hot], axis=0)\n","\n","    return y_true_smoothed\n","\n","def accuracy(y_true, y_pred):\n","\n","  y_pred = tf.cast(tf.argmax(y_pred, axis=-1), tf.float32)\n","  N = tf.math.count_nonzero(y_true, dtype=tf.float32)\n","\n","  return tf.math.reduce_sum(tf.cast(tf.math.equal(y_true, y_pred), tf.float32))/N\n","\n","class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","\n","  def __init__(self, d_model, warmup_steps,k):\n","    super(CustomSchedule, self).__init__()\n","\n","    self.d_model = d_model\n","    self.d_model = tf.cast(self.d_model, tf.float32)\n","\n","    self.warmup_steps = warmup_steps\n","    self.k = k\n","\n","  def __call__(self, step):\n","    arg1 = tf.math.rsqrt(step)\n","    arg2 = step * (self.warmup_steps**-1.5)\n","\n","    return self.k*tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"faopLnPwLK3q","colab_type":"code","colab":{}},"source":["def create_model():\n","    model = transformer(\n","            vocab_size=C.VOCAB_SIZE,\n","            maximum_position_encoding=C.MAX_POSITION_ENCODING,\n","            num_layers_enc=C.N_ENC,\n","            num_layers_dec=C.N_DEC,   \n","            units=C.UNITS,\n","            d_spec=C.D_SPEC,\n","            d_model=C.D_MODEL,\n","            num_heads=C.NUM_HEADS,\n","            dropout=C.DROPOUT,\n","            cnn=C.CNN)\n","    \n","    learning_rate = CustomSchedule(C.D_MODEL, C.WARMUP_STEPS, C.K)\n","    optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=C.BETA1, beta_2=C.BETA2, epsilon=C.EPS)\n","    model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n","\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KhMmH7PYaYD0","colab_type":"text"},"source":["#Training"]},{"cell_type":"code","metadata":{"id":"xd0pQEP8aQNT","colab_type":"code","colab":{}},"source":["tf.keras.backend.clear_session()\n","\n","if C.TPU:\n","    with strategy.scope():\n","        model = create_model()\n","else:\n","    model = create_model()\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Gs4t_XmaaoL","colab_type":"code","colab":{}},"source":["path = C.CALLBACKS_PATH\n","\n","if not os.path.isdir(path):\n","    os.mkdir(path)\n","\n","callbacks = [tf.keras.callbacks.CSVLogger(os.path.join(path,'logs.csv'),append=True),\n","            tf.keras.callbacks.ModelCheckpoint(os.path.join(path,'checkpoints.h5'), save_weights_only=True, save_best_only=True),\n","            tf.keras.callbacks.ModelCheckpoint(os.path.join(path,'checkpoints_{epoch:04d}.h5'), save_weights_only=True)]\n","\n","if os.path.isfile(os.path.join(path,C.SAVED_MODEL)) and C.LOAD:\n","    model.load_weights(os.path.join(path,C.SAVED_MODEL))\n","    print ('Checkpoint restored')\n","    if C.TRAIN:\n","        epoch = int(C.SAVED_MODEL.split('_')[1][:4])\n","        model.optimizer.iterations.assign(epoch*len(spec_audio_train)//C.BATCH_SIZE)\n","        print(\"{} iterations trained\".format(model.optimizer.iterations.numpy()))\n","        print(\"{} epochs trained\".format(epoch))\n","else:\n","    print('first training')\n","    epoch = 0\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fgr_moQBadMa","colab_type":"code","colab":{}},"source":["if C.TRAIN:\n","    model.fit(dataset_train, epochs=C.EPOCHS, validation_data=dataset_val, callbacks=callbacks, initial_epoch=epoch)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uOmfGM8QafKr","colab_type":"text"},"source":["#Evaluation"]},{"cell_type":"code","metadata":{"id":"wJYohf4fahaB","colab_type":"code","colab":{}},"source":["def gready_search_decoding(input_encoder, model, tokenizer, config, verbose=0):\n","\n","    input_encoder = tf.expand_dims(input_encoder, axis=0)\n","    input_decoder = tf.expand_dims(config.START_TOKEN, axis=0)\n","\n","    for i in range(config.MAX_LENGTH):\n","        if verbose:\n","          if config.ENCODING == 'subword':\n","              sys.stdout.write(\"\\r{}\".format( tokenizer.decode([j for j in input_decoder.numpy()[0] if j < config.VOCAB_SIZE-2]) ))\n","          else:\n","              sys.stdout.write(\"\\r{}\".format( tokenizer.sequences_to_texts([[j for j in input_decoder.numpy()[0] if j < config.VOCAB_SIZE-2]]) ))\n","\n","        predictions = model(inputs=[input_encoder, input_decoder], training=False)\n","        predictions = predictions[:, -1:, :]\n","        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n","\n","        if tf.equal(predicted_id, config.END_TOKEN):\n","            break\n","\n","        input_decoder = tf.concat([input_decoder, predicted_id], axis=-1)\n","\n","    if verbose:\n","        print()\n","\n","    if config.ENCODING == 'subword':\n","        return tokenizer.decode([i for i in tf.squeeze(input_decoder, axis=0).numpy() if i < config.VOCAB_SIZE-2])\n","    else:\n","        return tokenizer.sequences_to_texts([[i for i in tf.squeeze(input_decoder, axis=0).numpy() if i < config.VOCAB_SIZE-2]])[0][::2]\n","\n","\n","def beam_search_decoding(input_encoder, model, tokenizer, config, verbose=0):\n","\n","    input_encoder = tf.expand_dims(input_encoder, axis=0)\n","    input_decoder = tf.expand_dims(config.START_TOKEN, axis=0)\n","\n","    k_scores = [0.0]\n","\n","    for i in range(config.MAX_LENGTH):\n","        if verbose:\n","            print('\\nStep', i)\n","            if config.ENCODING == 'subword':\n","                for k in range(input_decoder.shape[0]):\n","                    print( tokenizer.decode([j for j in input_decoder.numpy()[k] if j < config.VOCAB_SIZE-2]) )\n","            else:\n","                for k in range(input_decoder.shape[0]):\n","                    print( tokenizer.sequences_to_texts([[j for j in input_decoder.numpy()[k] if j < config.VOCAB_SIZE-2]]) )\n","        predictions = model(inputs=[input_encoder, input_decoder], training=False)\n","        predictions = predictions[:, -1:, :]\n","        values, indices = tf.math.top_k(tf.math.log(tf.nn.softmax(predictions)), config.BEAM_SIZE)\n","\n","        sequences = []\n","        scores = []\n","\n","        for k in range(input_decoder.shape[0]):\n","            for b in range(config.BEAM_SIZE):\n","                sequences.append(tf.concat([input_decoder[k], [indices[k,0,b]]], axis=0))\n","                if i>=config.MAX_REP and len(tf.unique(sequences[-1][-config.MAX_REP:])[0])==1:\n","                    scores.append(k_scores[k] - float('inf'))\n","                else:\n","                    scores.append(k_scores[k] + values[k,0,b])\n","\n","        values, indices = tf.math.top_k(scores, config.BEAM_SIZE)\n","          \n","        k_scores = []\n","        input_decoder = []\n","        for k in range(config.BEAM_SIZE):\n","            k_scores.append(values[k])\n","            input_decoder.append(sequences[indices[k]])\n","        input_decoder = tf.stack(input_decoder)\n","\n","        if input_encoder.shape[0] == 1:\n","            input_encoder = tf.repeat(input_encoder, config.BEAM_SIZE, axis=0)\n","\n","        if tf.equal(input_decoder[0,-1], config.END_TOKEN):\n","            break\n","\n","    if verbose:\n","        print()\n","\n","    if config.ENCODING == 'subword':\n","        return tokenizer.decode([i for i in input_decoder[0].numpy() if i < config.VOCAB_SIZE-2])\n","    else:\n","        return tokenizer.sequences_to_texts([[i for i in input_decoder[0].numpy() if i < config.VOCAB_SIZE-2]])[0][::2]\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q1ZpKkeJdRml","colab_type":"code","colab":{}},"source":["s = tf.random.uniform([], 0, len(spec_audio_train), dtype=tf.int32)\n","\n","print('Input Spec : {}'.format(spec_audio_train[s].shape))\n","plt.matshow(tf.transpose(tf.cast(spec_audio_train[s], tf.float32)), origin='lower')\n","plt.show()\n","\n","pred = beam_search_decoding(spec_audio_train[s], model, tokenizer, C, verbose=1)\n","if C.ENCODING == 'subword':\n","    print('Speech : \\n{}'.format( tokenizer.decode([i for i in tokenized_speech_train[s] if i < C.VOCAB_SIZE-2]) ))\n","else:\n","    print('Speech : \\n{}'.format( tokenizer.sequences_to_texts([[i for i in tokenized_speech_train[s] if i < C.VOCAB_SIZE-2]])[0][::2] ))\n","print('Prediction : \\n{}'.format( pred ))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W1ogR8-u1Vrz","colab_type":"code","colab":{}},"source":["s = tf.random.uniform([], 0, len(spec_audio_val), dtype=tf.int32)\n","\n","print('Input Spec : {}'.format(spec_audio_val[s].shape))\n","plt.matshow(tf.transpose(tf.cast(spec_audio_val[s], tf.float32)), origin='lower')\n","plt.show()\n","\n","pred = beam_search_decoding(spec_audio_val[s], model, tokenizer, C, verbose=0)\n","if C.ENCODING == 'subword':\n","    print('Speech : \\n{}'.format( tokenizer.decode([i for i in tokenized_speech_val[s] if i < C.VOCAB_SIZE-2]) ))\n","else:\n","    print('Speech : \\n{}'.format( tokenizer.sequences_to_texts([[i for i in tokenized_speech_val[s] if i < C.VOCAB_SIZE-2]])[0][::2] ))\n","print('Prediction : \\n{}'.format( pred ))"],"execution_count":null,"outputs":[]}]}